---
---

## Maintaining large datasets at scale

[Current version of talk](talk/)

### Archived releases

```{python}

#| echo: false
#| output: asis

# this uses the GitHub API to find a all releases for this repo
import os
from github import Github
import pandas as pd
import requests
from git import Repo


# get info about present repo
assert os.path.exists('../.git'), 'This code must be run from within the site subdirectory'
repo_obj = Repo('../')

repo_name = repo_obj.remotes.origin.url.removesuffix('.git').rsplit('/', 1)[1]

## use github api to find releases
# Github username
username = "effigies"
# pygithub object

token_file = os.path.join(repo_obj.working_dir, '.token')
if os.path.exists(token_file):
    with open(token_file) as f:
        token = f.read().strip()

g = Github(token)

# get that user by username
user = g.get_user(username)


repo_info = g.get_repo(f'{user.login}/{repo_name}')
releases = list(repo_info.get_releases())

site_base = 'https://effigies.github.io/' + repo_name.split('/')[-1]

for release in releases:
    release_date = release.published_at.strftime('%Y-%m-%d')
    print(f'{release_date}: {release.title}')
    print(f"\n- [PDF]({os.path.join(site_base, 'pdfs', release.name + '.pdf')}) [Full release]({release.html_url})")
    print('\n\n')

```

